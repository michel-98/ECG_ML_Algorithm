# Defense Strategies of a Federated Learning system attacked by Label Flipping  

This Python script shows a federated learning system attacked with label flipping using 3 different defense strategies of data sanitization (substitution, deletion, data augmentation).
It uses Flower (FL) library for federated learning simulation.

## Features

- Federated learning setup with client-server architecture.
- Label flipping attack on client data partitions.
- Custom defense strategies against label flipping attacks.
- Evaluation of federated learning performance.

## Installation

#### pip

Write the command below in your terminal to install the dependencies according to the configuration file requirements.txt.

```shell
pip install -r requirements.txt
```

### Run Federated Learning Example

## Usage

1. Run the Python script `sim.py`.
```bash
python sim.py
```
2. Enter the necessary parameters:
   - Attacked (True/False): Specifies whether the system is under attack or not.
   - Defense Strategy (0/1/2/3):
     - 0: No defense
     - 1: Substitution
     - 2: Deletion
     - 3: Data augmentation
   - Attacked Clients (1-3): Number of clients targeted for attack.
   - Attacked Percentage: Percentage of labels to be flipped during the attack.
3. The script executes federated learning with the provided parameters.

## Components

- `main.py`: Main script to run federated learning simulation.
- `ECG.py`: Data preprocessor for handling Electrocardiogram (ECG) data.
- `flower_client.py`: Flower client class for federated learning.
- `parameter.py`: Contains global parameters for the simulation.
- `utils.py`: Utility functions for attack and defense strategies.

## Customization

You can customize the defense strategies, attack scenarios, and evaluation metrics based on your requirements. 

## References

- [Flower GitHub Repository](https://github.com/adap/flower)
- [scikit-learn Documentation](https://scikit-learn.org/stable/documentation.html)

## Contributors

- [Michele Antonacci]

## License

[MIT](https://opensource.org/licenses/MIT)